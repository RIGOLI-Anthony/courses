{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à PyTorch : AutoGrad\n",
    "\n",
    "----\n",
    "\n",
    "Cette partie du cours permet juste de se servir de la feature autoGrad. Mais qu'est-ce c'est que l'autoGrad ???\n",
    "\n",
    "L'autoGrad est simplement une feature qui permet de calculer directement les matrices jacobiennes issues des opérations sur les tenseurs avec ou sans paramètres. En fait c'est simplement un outil qui nous permet d'obtenir la matrice des gradients pour appliquer notre optimiseur par derrière pour la partie back-propagation ! Tout est géré automatiquement donc aucun calculs n'est nécessaire.\n",
    "\n",
    "En ce qui concerne son utilisation, le but est de suivre les entrées du réseau pour y vérifier toutes les opérations. A la sortie du réseau nous avons ainsi la sortie que l'on veut comparer à la fonction de coût. Ainsi le but est de bien entendu trouver le gradient entre les paramètres et la fonction de coût. La règle de la chaîne nous fait ainsi remonter toutes les opérations du réseau et son application par la fonction de coût. Le calcul du gradient se fera ainsi à la toute fin lors de la sortie du réseau et après l'application de la fonction de coût."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour utiliser la feature d'autoGrad, on va devoir spécifier quels tenseurs on veut suivre pour calculer son gradient au fur et à mesure des opérations qui lui sont appliqués :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du tenseur qu'on veut suivre :\n",
    "\n",
    "x = torch.tensor([1., 2., 3.], requires_grad=True) # Rajouter requires_grad=True permet de suivre le tenseur x. On peut alors observer son gradient par rapport à d'autres tenseurs.\n",
    "\n",
    "y = x + 2 # y est un tenseur qui dépend de x et qu'on veut suivre. Ainsi on peut observer un attribut de y, son gradient par rapport à x.\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "print(y.grad_fn) # y a été créé par une opération, on peut donc observer l'opération qui a créé y.\n",
    "# L'opération en question (AddBackward) a été créée par l'addition de x et 2 et est visible à l'adresse spécifiée.\n",
    "\n",
    "# Maintenant que se passe-t-il quand on change d'opération ?\n",
    "\n",
    "z = y * y * 3\n",
    "\n",
    "print(z) # On observe alors un nouveau gradient function nommé MulBackward0, créé par la multiplication de y par y par 3. \n",
    "\n",
    "z = z.mean()\n",
    "\n",
    "print(z) # MeanBackward0 (encore une autre opération suivie)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant qu'on a effectué tout un tas d'opération qui on pour origine le tenseur x qui est suivi, on peut alors calculer son gradient très facilement par une application de la règle de la chaine :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.grad) # On observe que le gradient de x par rapport à z est None, car on n'a pas encore fait de backward sur z.\n",
    "\n",
    "z.backward() # On calcule le gradient de z par rapport à x.\n",
    "\n",
    "print(x.grad) # On observe le gradient de x par rapport à z avec une application de la règle de la chaine pour remonter toutes les opérations précédentes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Remarque importante</u> : On ne peut pas effectuer deux fois l'opération du calcul de gradient, donc il faut bien faire attention de bien effectuer cette opération une fois que tous les calculs sont à priori terminés et à gérer de façon intelligente pour pas qu'il s'exécute deux fois ou plus... C'est ce qui arrivera notamment lorsque l'on itère sur plusieurs épochs sans vider le gradient, on accumulera ainsi les gradients de chaque épochs, faussant ainsi lourdement le résultat."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Retirer les tenseurs de l'autoGrad et remarque :\n",
    "\n",
    "Maintenant que l'on a vu comment suivre des tenseurs, il faut bien comprendre que ce que l'on veut suivre c'est bien entendu <u>**les paramètres**</u> car ce sont eux que l'on veut regarder pour le gradient de la fonction de coût. L'idée est alors que l'on suit les paramètres durant un epoch, on réinitialise le gradient et on sort les paramètres de l'autoGrad. En effet à chaque fin d'epoch, on veut mettre à jour les paramètres. Cependant cette opération ne rentre surtout pas en compte dans le processus de calcul de gradient, c'est pourquoi on veut retirer les paramètres de l'autoGrad à chaque fois et les remettre ensuite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous allons regarder deux méthodes en particulier :\n",
    "\n",
    "# Utilisation de 'x.require_grad_(false)' :\n",
    "\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x.requires_grad) # True\n",
    "x.requires_grad_(False)\n",
    "print(x.requires_grad) # False\n",
    "\n",
    "# Deuxième méthode plus propre :\n",
    "\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "with torch.no_grad(): # On désactive le gradient pour x.\n",
    "    print((x**2).requires_grad) # False\n",
    "    \n",
    "# with torch.no_grad() permet de désactiver le gradient pour un bloc de code. Cela en revanche ne change pas le gradient de x mais désactive le gradient pour le bloc de code.\n",
    "# Ainsi si on avait juste mis x, on aurait eu True, car x a toujours son gradient activé."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Application à l'implémentation d'un modèle de régression linéaire :\n",
    "\n",
    "On veut maintenant appliquer ce qu'on a vu à un modèle de régression linéaire. On veut ici approximer la fonction $ f : x → 2x $\n",
    "\n",
    "On va donc partir du modèle linéaire $ f : x → w*x + b $ (ici on fixe directement b à 0 pour simplifier...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On prend des données très simple de X et Y :\n",
    "\n",
    "X = torch.tensor([1,2,3,4,5,6,7,8], dtype=torch.float32)\n",
    "Y = torch.tensor([2,4,6,8,10,12,14,16], dtype=torch.float32) # Notre modèle va devoir prédire Y à partir de X.\n",
    "\n",
    "W = torch.tensor(0.0, dtype = torch.float32, requires_grad=True) # On rajoute bien entendu l'autograd pour W car on veut faire une rétropropagation par la suite.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On veut maintenant préciser les fonctions utiles à notre modèle :\n",
    "\n",
    "# Notre modèle est très simple, il s'agit d'une fonction linéaire, donc on va juste faire une multiplication pour avoir notre sortie après une propagation.\n",
    "def forward(x):\n",
    "    return W * x\n",
    "\n",
    "# On veut maintenant la fonction loss pour calculer l'erreur de notre modèle.\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted - y)**2).mean() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour l'instant on a nos paramètres à 0, on a donc un résultat de f(x) = 0 pour tout x...\n",
    "# On va alors commencer l'entraînement avec la définition de nos paramètres :\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_epoch = 100\n",
    "\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "\n",
    "    y_pred = forward(X) # On calcule la prédiction de notre modèle.\n",
    "    \n",
    "    l = loss(Y, y_pred) # On calcule la loss de notre modèle.\n",
    "    \n",
    "    # Maintenant que l'on a tout ça, on va pouvoir faire la rétropropagation :\n",
    "\n",
    "    l.backward() # On calcule le gradient de l par rapport à W.\n",
    "\n",
    "    # Vient ensuite la mise à jour des poids (sans autoGrad du coup !!!) :\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        W -= learning_rate * W.grad # On met à jour W.\n",
    "        \n",
    "    # On remet à 0 le gradient de W pour la prochaine itération :\n",
    "    W.requires_grad_(True) # On réactive le gradient de W pour la prochaine itération.\n",
    "    W.grad.zero_()\n",
    "    \n",
    "    # On affiche la loss à chaque 10 itérations :\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {W:.3f}, loss = {l:.8f}')\n",
    "        \n",
    "# Résultat de notre entraînement :\n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Remarque</u> : Petite remarque au niveau du code, on peut pas faire $W = W - learning\\_rate*W.grad$ sinon on change la variable W pour qu'elle perde son statut de require = True et dans ce cas elle ne peut pas contenir d'élément 'grad' ce qui cause une erreur.\n",
    "Le fait de faire l'opération $ W -= learning\\_rate*W.grad$ en revanche modifie bien W sans pour autant retirer le statut de require = True ce qui est plus avantageux (c'est sombre comme feature...)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Voilà ce qui concerne l'utilisation de l'autoGrad qui est extrêmement utile pour calculer les gradients pour pouvoir les utiliser dans les algorithmes d'optimisation. La manière dont sera calculée le gradient sera sensiblement toujours pareille. En effet, la boucle utilisée pour notre descente de gradient est un exemple à peine simplifié de ce que l'on va implémenter dans les prochains cours pour créer des réseaux de neurones.\n",
    "\n",
    "*Remarque très importante* :\n",
    "\n",
    "Connaître l'autograd est utile pour comprendre un peu mieux l'exécution d'une boucle d'entraînement PyTorch car en effet, on définit toujours soi-même la boucle. **CEPENDANT**, son utilisation dans un réseau de neurones est extrêmement simplifiée (les poids sont initialisés avec un suivi automatique et on a juste besoin d'appeler la fonction de backward en fait). C'est pourquoi connaître l'autograd peut sembler un peu inutile. Or ce n'est très loin d'être vrai car beaucoup de travaux de recherches ou de développement d'outils en science des données et ML se font avec non pas des réseaux mais des algorithmes d'optimisations numériques itératifs (même genre qu'une descente de gradient) et l'implémentation s'avère compliqué sans moyen de calculer les gradients. C'est pourquoi nombres de ces outils sont implémentés en PyTorch pour avoir accès à l'autograd. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
