{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à PyTorch : Dernier cours sur la construction des modèles\n",
    "\n",
    "----\n",
    "\n",
    "Cette partie est la dernière partie de cette série de cours et traite de la création de modèles. Elle constitue alors un approfondissement car c'est là que réside les variantes dans l'utilisation de PyTorch...\n",
    "\n",
    "Ce qui va alors s'avérer important est de comprendre comment sont implémentées les couches de notre réseau avec PyTorch, comment les incorporer dans notre modèle efficacement et finalement comment les appliquer sur nos données correctement.\n",
    "\n",
    "Ainsi nous allons voir le cas d'un réseau simple de classification avec l'utilisation de fonction d'activation (non utilisée jusqu'à maintenant), le cas d'un CNN pour de la classification d'images simples et pour finir, un RNN simple et pour finir une application sur une architecture plus compliquée sera mise dans un fichier à part qui constituera alors la dernière étude de cas pour clôturer ce cours (on verra un U-net, l'architecture étant très visuelle mais assez complexe).\n",
    "\n",
    "----\n",
    "\n",
    "## Préparation des données:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "# from multiprocessing import freeze_support\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # GPU or CPU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Cifar10 pour le CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # ça permet de transformer les données en tenseurs et de les normaliser quand on les récupère des datasets\n",
    "\n",
    "batch_size_cifar = 4\n",
    "\n",
    "trainset_cifar10 = torchvision.datasets.CIFAR10(root='./PyTorch_ver/data_pytorch', train=True,\n",
    "                                        download=True, transform=transform) # On charge le dataset avec les transformations\n",
    "\n",
    "trainloader_cifar10 = torch.utils.data.DataLoader(trainset_cifar10, batch_size=batch_size_cifar,\n",
    "                                        shuffle=True, num_workers=2) # On charge le dataset dans un loader qui nous permettra de le parcourir avec une boucle for\n",
    "\n",
    "testset_cifar10 = torchvision.datasets.CIFAR10(root='./PyTorch_ver/data_pytorch', train=False,\n",
    "                                    download=True, transform=transform)\n",
    "testloader_cifar10 = torch.utils.data.DataLoader(testset_cifar10, batch_size=batch_size_cifar,\n",
    "                                        shuffle=False, num_workers=2) # Pareil qu'avec le trainloader\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "        'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST pour le classifieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "input_size = 784 # Les images sont de taille 28*28 = 784\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 11\n",
    "batch_size_mnist = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "#MNIST Dataset :\n",
    "train_dataset_mnist = torchvision.datasets.MNIST(root='./PyTorch_ver/data_pytorch', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset_mnist = torchvision.datasets.MNIST(root='./PyTorch_ver/data_pytorch', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader_mnist = torch.utils.data.DataLoader(dataset=train_dataset_mnist, batch_size=batch_size_mnist, shuffle=True)\n",
    "\n",
    "test_loader_mnist = torch.utils.data.DataLoader(dataset=test_dataset_mnist, batch_size=batch_size_mnist, shuffle=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Définition du modèle:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # (input_channels, output_channels, kernel_size)\n",
    "        self.pool = nn.MaxPool2d(2, 2) # (kernel_size, stride)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # le 16*5*5 correspond au nombre de filtres de la couche de convolution précédente fois le kernel size (5x5)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "        # On a donc définie un total de 6 couches : 2 couches de convolution, 3 couches linéaires et une couche de pooling\n",
    "        # On doit impérativement définir ici le nombre de layer correspondant à l'architecture du réseau. La raison pour cela est que\n",
    "        # chaque couches est définie par un module nn.Module et contient ainsi des paramètres qui seront optimisés par le réseau de neurones.\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x) # On applique la première couche de convolution\n",
    "        x = F.relu(x) # On applique la fonction d'activation\n",
    "        x = self.pool(x) # On applique la couche de pooling\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv2(x))) # On effectue les 3 opérations précédentes en une seule ligne\n",
    "        \n",
    "        x = torch.flatten(x, 1) # On applati les tenseurs pour les passer dans les couches linéaires (sauf la première dimension qui est la taille du batch)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # On définit ici la fonction forward qui permet de définir le passage des données dans le réseau de neurones.\n",
    "        # On peut littéralement voir ça comme une fonction mathématique qui prend en entrée un tenseur et qui renvoie un tenseur et rien de plus.\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size = input_size, hidden_size = hidden_size, num_classes= num_classes):\n",
    "        \n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.dense = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        self.relu = nn.ReLU() # Autre manière d'utiliser la fonction d'activation\n",
    "        \n",
    "        self.dense_1 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.dense(x)\n",
    "        \n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.dense_1(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Définition de la boucle d'entraînement:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.to(device) # On envoie le modèle sur le GPU si on en a un pour que tout l'entrainement se fasse sur le GPU\n",
    "\n",
    "criterion_cnn = nn.CrossEntropyLoss()\n",
    "optimizer_cnn = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(4):  # Boucle sur un nombre d'epoch de 4\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader_cifar10, 0): # On parcourt le trainloader donc tout le dataset\n",
    "            \n",
    "            inputs, labels = data \n",
    "\n",
    "            # Ici on met les gradients à zéro pour ne pas qu'ils s'accumulent et faussent tout\n",
    "            optimizer_cnn.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion_cnn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer_cnn.step() # MAJ des poids\n",
    "\n",
    "            # Partie affichage des résultats\n",
    "            running_loss += loss.item() # On ajoute la loss à la running_loss (somme de la loss sur tout les mini-batchs)\n",
    "            if i % 2000 == 1999:    # On print tout les 2000 mini-batchs\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes importantes:\n",
    "\n",
    "- En ce qui concerne la boucle on peut aussi la personnaliser, l'encapsuler dans une fonction etc... Ici elle est simplement à la suite du code (cas basique).\n",
    "\n",
    "- La boucle commence par : \n",
    "```python \n",
    "    for i, data in enumerate(trainloader_cifar10, 0): \n",
    "```\n",
    "Or qu'est-ce que le enumerate ?? C'est une classe en python qui prend en entrée ce qu'on appelle un générateur et dont le but est de fournir deux éléments dans une boucle for. Le premier élément est notre $i$ qui est un compteur et notre deuxième élément est $data$ qui est un objet issu du générateur. Ici notre générateur c'est notre $trainloader\\_cifar10$ et quand on l'a définie on a utilisé un objet $DataLoader$. La particularité de cet objet est qu'il permet de créer un générateur donnant comme objet un tuple (x, y) avec x notre input de notre model et y notre label\n",
    "\n",
    "Ainsi $i$ va compter les éléments présents dans un batch et $data$ est ainsi composé des inputs (donc une image) et de son label (donc une classe) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model = NeuralNetwork(), save = False, num_epochs = num_epochs):\n",
    "    \n",
    "    # loss and optimizer :\n",
    "    loss = nn.CrossEntropyLoss() # computes softmax and then the cross entropy so we don't need activation function at the output layer\n",
    "    # loss = nn.MSELoss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # We can now train the model :\n",
    "\n",
    "    n_steps = len(train_loader_mnist)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader_mnist):\n",
    "            \n",
    "            images = images.reshape(-1, 28*28).to(device) # Ici on fait un élément de préprocessing pour avoir les images sous la forme d'un vecteur de taille 784\n",
    "                                                          # et on met sur le GPU si on en a un\n",
    "                                                          \n",
    "            labels = labels.to(device) # On met les labels sur le GPU si on en a un\n",
    "            \n",
    "            # Forward + Backward + Optimize : \n",
    "            \n",
    "            outputs  = model.forward(images) # Même chose que model(images) mais on utilise la fonction forward pour être plus explicite ici \n",
    "            l = loss(outputs, labels)\n",
    "            \n",
    "            l.backward()\n",
    "            optimizer.step() # On met à jour les paramètres du modèle\n",
    "            optimizer.zero_grad() # On met les gradients à zéro pour ne pas qu'ils s'accumulent et faussent tout\n",
    "            \n",
    "            if (i+1)%100 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_steps}], Loss: {l.item():.4f}')\n",
    "    if save:\n",
    "        torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "\n",
    "Ici on a donc un classifieur d'image et on a utilisé une fonction pour l'entraînement plutôt qu'une boucle. Cela permet donc diverses variations comme le fait de rajouter une sauvegarde de nos poids par exemple ou de changer le nombre d'epoch facilement.\n",
    "\n",
    "On pourra aussi noter l'utilisation de la commande :\n",
    "```py\n",
    "    torch.save(model.state_dict(), 'model.pt')\n",
    "```\n",
    "\n",
    "qui se sert d'un dictionnaire qu'il stock dans un fichier .pt. Ce dictionnaire contient tous les poids du réseau, c'est donc une ligne très importante."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Conclusion :\n",
    "\n",
    "Voilà on a vu deux applications avec deux réseaux différents avec leur pipeline respectives et quelques idées de variantes. Ces variantes permettent de voir comment encapsuler des parties de la pipelines, modifier les hyper-paramètres à divers endroits ou les variantes dans l'affichage ou encore la manière d'appliquer les couches aux inputs dans le réseau. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
